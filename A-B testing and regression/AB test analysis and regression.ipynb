{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze A/B Test Results\n",
    "\n",
    "#### Author/Analyst: Leon Hamnett\n",
    "#### [LinkedIn](https://www.linkedin.com/in/leon-hamnett/)\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)\n",
    "- [Part IV - Conclusions](#conclusions) \n",
    "\n",
    "\n",
    "<a id='intro'></a>\n",
    "### Introduction\n",
    "\n",
    "In this notebook we will be working to understand the results of an A/B test run by an e-commerce website. Throughout this notebook we will try to help the company understand if they should implement a new page design, keep the old page design, or perhaps run the experiment longer to make their decision.\n",
    "\n",
    "In the data we can see a user_id, a time when they accessed the page, and whether they were in the control group and were shown the old website page or in the 'treatment' group and were shown the new version of the website. We also see if they were converted to spend money on the website.\n",
    "\n",
    "To come up with an actionable decision, we will be using a mix of techniques; incuding probability, A/B tests (sampling distributions and z-statistics) and logistic regression.\n",
    "\n",
    "\n",
    "<a id='probability'></a>\n",
    "#### Part I - Probability\n",
    "\n",
    "Firstly we'll examine the data using probabilities.\n",
    "\n",
    "We'll import the libaries we'll be using during the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read and examine the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ab_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294478"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of unique users in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['user_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Check the proportion of users converted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1194418598333322"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check unique users who converted\n",
    "uniq_convert = df.query('converted == \"1\"').groupby(by='user_id',axis=0)\n",
    "#check proportion of unique users who converted\n",
    "prop_convert = len(uniq_convert)/df.shape[0]\n",
    "prop_convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Check the number of times the `new_page` and `treatment` columns don't match as this shows an error in the data as these should always match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control and new page mismatch:  1928\n",
      "treatment and old page mismatch:  1965\n",
      "total mismatches:  3893\n"
     ]
    }
   ],
   "source": [
    "a= len(df[(df['group']=='control') & (df['landing_page']=='new_page')])\n",
    "b = len(df[(df['group']=='treatment') & (df['landing_page']=='old_page')])\n",
    "print('control and new page mismatch: ',a)\n",
    "print('treatment and old page mismatch: ',b)\n",
    "print('total mismatches: ',a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if any of the rows have missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 294478 entries, 0 to 294477\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   user_id       294478 non-null  int64 \n",
      " 1   timestamp     294478 non-null  object\n",
      " 2   group         294478 non-null  object\n",
      " 3   landing_page  294478 non-null  object\n",
      " 4   converted     294478 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 11.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "#we see no rows have missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rows where **treatment** does not match with **new_page** or **control** does not match with **old_page**, we cannot be sure if this row truly received the new or old page. We will investigate further to see if we can see a pattern or another method to correct this incorrect data. \n",
    "\n",
    "Create a new dataframe with just the mismatched rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mismatched rows:  3893\n",
      "original row count:  294478\n",
      "new row count:  290585\n"
     ]
    }
   ],
   "source": [
    "#create new data frame with all mismatched rows\n",
    "mismatch = df[(df['group']=='control') & (df['landing_page']=='new_page')]\n",
    "mismatch2 = df[(df['group']=='treatment') & (df['landing_page']=='old_page')]\n",
    "mismatch_all = pd.concat([mismatch,mismatch2],axis=0,join='outer')\n",
    "# check rows affected for similarities\n",
    "print('mismatched rows: ',mismatch_all.shape[0])\n",
    "#we have no method to verify which value is correct\n",
    "#as number of rows is not a large percentage of total rows, we can drop these rows\n",
    "df2 = df.drop(index=mismatch_all.index)\n",
    "#check rows have been deleted correctly\n",
    "print('original row count: ',df.shape[0])\n",
    "print('new row count: ',df2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check all of the rows with this error were removed \n",
    "df2[((df2['group'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many unique **user_id**s are in **df2** (dataframe with incorrect values for treatment removed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2['user_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Check for duplicate rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[df2['user_id'].duplicated()==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check duplicate entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[df2['user_id']==773192]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove one of the rows with a duplicate **user_id**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we choose to keep the earliest instance of the duplicate\n",
    "#drop the second instance\n",
    "df2.drop(index=2893,inplace=True)\n",
    "#check dup has been removed\n",
    "df2.loc[df2['user_id']==773192]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what is the probability of an individual converting regardless of the page they receive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we find the probability of an unique individual converting\n",
    "prob_convert = len(df2.query('converted==\"1\"').groupby(by='user_id'))/len(df2.groupby(by='user_id'))\n",
    "prob_convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that an individual was in the `control` group, we check the probability they converted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we find the probability of an unique individual converting if they were in the control group\n",
    "control = df2.query('group==\"control\"')\n",
    "prob_control_converted = len(control.query('converted==\"1\"').groupby(by='user_id'))/len(control.groupby(by='user_id'))\n",
    "prob_control_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that an individual was in the `treatment` group, we check the probability they converted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880806551510564"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we find the probability of an unique individual converting if they were in the treatment group\n",
    "treatment = df2.query('group==\"treatment\"')\n",
    "prob_treat_converted = len(treatment.query('converted==\"1\"').groupby(by='user_id'))/len(treatment.groupby(by='user_id'))\n",
    "prob_treat_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the probability that an individual received the new page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000619442226688"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we find the probability of an unique individual being shown the new page\n",
    "prob_new_page = len(df2.query('landing_page==\"new_page\"').groupby(by='user_id'))/len(df2.groupby(by='user_id'))\n",
    "prob_new_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inferences:\n",
    "\n",
    "Considering that we see the probability an individual converts, is almost the same whether they were shown the old page or the new page, and the probability an individual converts when shown the new page is almost the same as the chance an indivual converts regardless of the page they were shown. \n",
    "\n",
    "I would conclude there is not sufficient evidence to decide with certainty that the new page leads to more conversions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### Part II - A/B Test\n",
    "\n",
    "Secondly we'll examine the data using hypothesis tests to check the results of the a/b test.\n",
    "\n",
    "We assume that the old page is better unless the new page proves to be definitely better at a Type I error rate of 5% (0.95 confidence) and thus set up the null and alternative hypothesis' as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_{0}$ (null) : $P_{new}$ - $P_{old}$  <= 0\n",
    "\n",
    "$H_{A}$  (alternative) : $P_{new}$ - $P_{old}$  > 0 \n",
    "\n",
    "Where P-new is the proportion of users who convert after being shown the new page and P-old is the proportion of users who convert even when they were shown the old page (baseline)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: Edge case and simulated distribution:\n",
    "\n",
    "The method we will use in the first case to evaluate the null hypothesis is to take an edge value, one that is within the null hypothesis but is very close to being in the alternative hypothesis. In this case when the difference in propertions is zero. We will then check the sampling distribution for this case and then see where our actual data falls within the distribution.\n",
    "\n",
    "First we assume under the null hypothesis, $p_{new}$ and $p_{old}$ both have \"true\" success rates equal to the **converted** success rate regardless of page - that is $p_{new}$ and $p_{old}$ are equal. Furthermore, we assume they are equal to the **converted** rate in **ab_data.csv** regardless of the page a user sees. <br><br>\n",
    "\n",
    "We use a sample size for each page equal to the sample sizes in **ab_data.csv**.  And then we will create the sampling distribution for the difference in **converted** between the two pages over 10,000 iterations of calculating an estimate from the null.  <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the **conversion rate** for $p_{new}$ under the null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find conversion rate for p-new\n",
    "new_cr = prob_convert\n",
    "new_cr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the **conversion rate** for $p_{old}$ under the null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find conversion rate for p-old\n",
    "old_cr = prob_convert\n",
    "old_cr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check $n_{new}$, the number of individuals in the treatment group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find number of unique users in the treatment group\n",
    "num_treat = len(df2.query('group==\"treatment\"').groupby(by='user_id'))\n",
    "num_treat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check $n_{old}$, the number of individuals in the control group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find number of unique users in the control group\n",
    "num_control = len(df2.query('group==\"control\"').groupby(by='user_id'))\n",
    "num_control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will simulate $n_{new}$ transactions with a conversion rate of $p_{new}$ under the null.  Then we store these $n_{new}$ 1's and 0's in **new_page_converted**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we simulate a new set of values for p-new\n",
    "new_page_converted = np.random.choice([0,1],num_treat,replace=True,p=[1-new_cr,new_cr])\n",
    "new_page_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will simulate $n_{old}$ transactions with a conversion rate of $p_{old}$ under the null. Then we store these $n_{old}$ 1's and 0's in **old_page_converted**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we simulate a new set of values for p-old\n",
    "old_page_converted = np.random.choice([0,1],num_control,replace=True,p=[1-old_cr,old_cr])\n",
    "old_page_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will find $p_{new}$ - $p_{old}$ for the simulated values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0017986761154338005"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we check the difference between the proportions\n",
    "prop_diff = new_page_converted.mean()-old_page_converted.mean()\n",
    "prop_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the sample distribution by running this process 10,00 times to get 10,000 mean/proportion differences. We will store all 10,000 values in a NumPy array called **p_diffs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create an empty list to house the difference values\n",
    "p_diffs = []\n",
    "#for each simulation, we create new distributions and thus new values for p-new and p-old\n",
    "# then in each iteration we find the difference of these values and add the difference to a list\n",
    "for x in range(10000):\n",
    "    new_page_converted = np.random.choice([0,1],num_treat,replace=True,p=[1-new_cr,new_cr])\n",
    "    old_page_converted = np.random.choice([0,1],num_control,replace=True,p=[1-old_cr,old_cr])\n",
    "    diff = new_page_converted.mean()-old_page_converted.mean()\n",
    "    p_diffs.append(diff)\n",
    "#check the for loop has run correctly\n",
    "len(p_diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot a histogram of the **p_diffs** to make sure it looks like what we expect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  24.,  151.,  778., 2006., 2930., 2542., 1163.,  340.,   63.,\n",
       "           3.]),\n",
       " array([-0.00434535, -0.0034203 , -0.00249524, -0.00157019, -0.00064514,\n",
       "         0.00027992,  0.00120497,  0.00213003,  0.00305508,  0.00398014,\n",
       "         0.00490519]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#look at the histogram for the proportion differences\n",
    "plt.hist(p_diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the central limit theorem, we see the histogram is normally distributed which is what we would expect. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check the proportion of the **p_diffs** which are greater than the actual difference observed in **ab_data.csv**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.9063\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#actual difference in data\n",
    "diff_actual = prob_treat_converted - prob_control_converted\n",
    "diff_actual\n",
    "#proportion of p_diffs\n",
    "p_diffs_df = pd.DataFrame(p_diffs) #change numpy array into pandas dataframe \n",
    "(p_diffs_df>diff_actual).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation of results for Method 1:\n",
    "\n",
    "The value that was just calculated is the p-value (significance level).\n",
    "\n",
    "This value was calculated by creating by looking at differences between two simulated normal distributions for the P-new and P_old values. This difference was calculated 10000 times using different normal distributions each time to create a simulated distribution for the values the difference could take. \n",
    "\n",
    "We then check our actual value of differences from the dataset against our simulated values, and see what proportion of our simulated disribution is higher than our actual value. \n",
    "\n",
    "Since **we obtain a high p-value much higher than the significance level (0.05)**, this means it is **highly likely that our actual value could have come from our simulated distribution** and so w**e fail to reject the null hypothesis**. \n",
    "\n",
    "#### We can say there is not significant evidence that the new page increases conversion rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: Using Z-test to check data against null:\n",
    "\n",
    "We will also use some built-in functions to check the above process and hopefully achieve similar results.  \n",
    "\n",
    "First we calculate the number of conversions for each page, as well as the number of individuals who received each page. Let `n_old` and `n_new` refer the the number of rows associated with the old page and new pages, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "#unique users who converted\n",
    "uniq_convert2 = df2.query('converted == \"1\"')\n",
    "#get amount of unique users who converted when shown the old page and new page\n",
    "convert_old = len(uniq_convert2.query('landing_page==\"old_page\"').groupby(by='user_id'))\n",
    "convert_new = len(uniq_convert2.query('landing_page==\"new_page\"').groupby(by='user_id'))\n",
    "#get the amount of unique users in total who were shown the old page and the new page\n",
    "n_old = len(df2.query('landing_page==\"old_page\"').groupby(by='user_id'))\n",
    "n_new = len(df2.query('landing_page==\"new_page\"').groupby(by='user_id'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the statsmodel function `stats.proportions_ztest` to compute the z-test statistic and associated p-value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.3109241984234394, 0.9050583127590245)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use the t-statistic to obtain z-score and a p-value for our dataset\n",
    "res = sm.stats.proportions_ztest([convert_new,convert_old],[n_new,n_old],value=0, alternative='larger', prop_var=False)\n",
    "res #outputs z score and p value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation of results for Method 2:\n",
    "\n",
    "The **negative z-score** shows that the **mean amount of users converted with the new page is 1.3 standard deviations below the mean amount of users converted who were shown the old page**\n",
    "\n",
    "The **p-value** is similar to the p-value calculated previously in method 1 and so the findings agree with each other. This new p-value also suggests as well that **since the p-value is much higher than the significance level**, we **fail to reject the null hypothesis**. We can say with statistical certainty there is no evidence that the new page obtains more conversions than the old page.\n",
    "\n",
    "### Inferences for both methods:\n",
    "\n",
    "We see from two different methods of hypothesis testing that the **p-value is high**, therefore our proportion differences in the data are very **likely to have been able to come from a distribution where the null hypothesis is true.**\n",
    "\n",
    "Therefore in both methods, **we fail to reject the null hypothesis** and accept with statistical certainty:\n",
    "\n",
    "p-new - p-old <= 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - A Logistical regression approach\n",
    "\n",
    "In this final part, we will see that the result we achieved in the A/B test in Part II above can also be achieved by performing regression.\n",
    "\n",
    "Since each row is either a conversion or no conversion, **the most appropiate type of regression to use in this case in a logistic regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this section is to use **statsmodels** to fit the regression model to see if there is a significant difference in conversion based on which page a customer receives. \n",
    "\n",
    "First we need to create in df2 a column for the model intercept, and create a dummy variable column for which page each user received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>936923</td>\n",
       "      <td>2017-01-10 15:20:49.083499</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>679687</td>\n",
       "      <td>2017-01-19 03:26:46.940749</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>719014</td>\n",
       "      <td>2017-01-17 01:48:29.539573</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>817355</td>\n",
       "      <td>2017-01-04 17:58:08.979471</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>839785</td>\n",
       "      <td>2017-01-15 18:11:06.610965</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>929503</td>\n",
       "      <td>2017-01-18 05:37:11.527370</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>834487</td>\n",
       "      <td>2017-01-21 22:37:47.774891</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>803683</td>\n",
       "      <td>2017-01-09 06:05:16.222706</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>944475</td>\n",
       "      <td>2017-01-22 01:31:09.573836</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>718956</td>\n",
       "      <td>2017-01-22 11:45:11.327945</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>644214</td>\n",
       "      <td>2017-01-22 02:05:21.719434</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>847721</td>\n",
       "      <td>2017-01-17 14:01:00.090575</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>888545</td>\n",
       "      <td>2017-01-08 06:37:26.332945</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>650559</td>\n",
       "      <td>2017-01-24 11:55:51.084801</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>935734</td>\n",
       "      <td>2017-01-17 20:33:37.428378</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id                   timestamp      group landing_page  converted  \\\n",
       "0    851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1    804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2    661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3    853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4    864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "5    936923  2017-01-10 15:20:49.083499    control     old_page          0   \n",
       "6    679687  2017-01-19 03:26:46.940749  treatment     new_page          1   \n",
       "7    719014  2017-01-17 01:48:29.539573    control     old_page          0   \n",
       "8    817355  2017-01-04 17:58:08.979471  treatment     new_page          1   \n",
       "9    839785  2017-01-15 18:11:06.610965  treatment     new_page          1   \n",
       "10   929503  2017-01-18 05:37:11.527370  treatment     new_page          0   \n",
       "11   834487  2017-01-21 22:37:47.774891  treatment     new_page          0   \n",
       "12   803683  2017-01-09 06:05:16.222706  treatment     new_page          0   \n",
       "13   944475  2017-01-22 01:31:09.573836  treatment     new_page          0   \n",
       "14   718956  2017-01-22 11:45:11.327945  treatment     new_page          0   \n",
       "15   644214  2017-01-22 02:05:21.719434    control     old_page          1   \n",
       "16   847721  2017-01-17 14:01:00.090575    control     old_page          0   \n",
       "17   888545  2017-01-08 06:37:26.332945  treatment     new_page          1   \n",
       "18   650559  2017-01-24 11:55:51.084801    control     old_page          0   \n",
       "19   935734  2017-01-17 20:33:37.428378    control     old_page          0   \n",
       "\n",
       "    intercept  ab_page  \n",
       "0           1        0  \n",
       "1           1        0  \n",
       "2           1        1  \n",
       "3           1        1  \n",
       "4           1        0  \n",
       "5           1        0  \n",
       "6           1        1  \n",
       "7           1        0  \n",
       "8           1        1  \n",
       "9           1        1  \n",
       "10          1        1  \n",
       "11          1        1  \n",
       "12          1        1  \n",
       "13          1        1  \n",
       "14          1        1  \n",
       "15          1        0  \n",
       "16          1        0  \n",
       "17          1        1  \n",
       "18          1        0  \n",
       "19          1        0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new copy of the dataframe and add an intercept column\n",
    "df3 = df2.copy()\n",
    "df3['intercept']=1\n",
    "#get dummy variables\n",
    "abdum = pd.get_dummies(df3['group'])\n",
    "#add dummy variables to a new column in the dataframe\n",
    "df3['ab_page']=abdum.iloc[:,[1]]\n",
    "#check\n",
    "df3.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use **statsmodels** to set up the regression model on the two columns we created. Then we will fit the model using the two columns to predict whether or not an individual converts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "#create a logistic regression model \n",
    "logm = sm.Logit(df3['converted'],df3[['intercept','ab_page']])\n",
    "res=logm.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the logistic regression summary table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>          <td>AIC:</td>        <td>212780.3502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2020-07-31 15:49</td>       <td>BIC:</td>        <td>212801.5095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>       <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>1</td>            <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290582</td>        <td>LLR p-value:</td>      <td>0.18988</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-1.9888</td>  <td>0.0081</td>  <td>-246.6690</td> <td>0.0000</td> <td>-2.0046</td> <td>-1.9730</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>-0.0150</td>  <td>0.0114</td>   <td>-1.3109</td>  <td>0.1899</td> <td>-0.0374</td> <td>0.0074</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.000      \n",
       "Dependent Variable: converted        AIC:              212780.3502\n",
       "Date:               2020-07-31 15:49 BIC:              212801.5095\n",
       "No. Observations:   290584           Log-Likelihood:   -1.0639e+05\n",
       "Df Model:           1                LL-Null:          -1.0639e+05\n",
       "Df Residuals:       290582           LLR p-value:      0.18988    \n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "No. Iterations:     6.0000                                        \n",
       "-------------------------------------------------------------------\n",
       "              Coef.   Std.Err.      z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept    -1.9888    0.0081  -246.6690  0.0000  -2.0046  -1.9730\n",
       "ab_page      -0.0150    0.0114    -1.3109  0.1899  -0.0374   0.0074\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the summary of the logistic regression \n",
    "res.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of Logistic regression results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value associated with ab_page is 0.1899. As this is higher than the level of significance, this means we **cannot reject the null hypothesis**. In this case the **null hypothesis is that the coefficient = 0**, in other words that the **independent variable has no impact on the dependent variable in the regression model**\n",
    "\n",
    "Whereas previously our null hypothesis was that there was not a difference between the conversion rates for the new page and old and was comparing two values. Here in the logistic regression, our null hypothesis is only whether a coefficient for a variable could be zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other factors to consider: ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, if we would want an accurate predictor of whether an individual converts or not, it would be a good idea to add other factors into our model. With the current factors, our model is not able to predict at all whether an individual will convert or not (shown by the pseudo-r-squared value of 0).\n",
    "\n",
    "The main danger in adding more variables is that if you are not careful, the variables could end up violating the assumptions of logistic regression.\n",
    "\n",
    "While these assumptions are less strict than for linear regression, there are still two which we should be aware of in this case:\n",
    "\n",
    "1) Logistic regression requires observations to be independent of each other\n",
    "\n",
    "2) Logistic regression requires there to be little or no multicollinearity among the independent variables [1](https://www.statisticssolutions.com/assumptions-of-logistic-regression/)\n",
    "\n",
    "To take into consideration the above two rules, we should take care not to include a variable and a derivative of that same variable in the same regression. Also after each variable is added we should check for multicolinearity and if we find multicolinearity, it would be wise to remove one of these variables causing the issue. \n",
    "\n",
    "Another danger is that by adding variables with an interaction or polynomial expression, this can make our interpretation of the results of the regression more difficult. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding additional variables to the Logistic regression:\n",
    "\n",
    "We will add the country of each user to see if this changes the results of the regression analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>country</th>\n",
       "      <th>canada</th>\n",
       "      <th>USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>936923</td>\n",
       "      <td>2017-01-10 15:20:49.083499</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>679687</td>\n",
       "      <td>2017-01-19 03:26:46.940749</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>719014</td>\n",
       "      <td>2017-01-17 01:48:29.539573</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>817355</td>\n",
       "      <td>2017-01-04 17:58:08.979471</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>UK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>839785</td>\n",
       "      <td>2017-01-15 18:11:06.610965</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>929503</td>\n",
       "      <td>2017-01-18 05:37:11.527370</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>UK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>834487</td>\n",
       "      <td>2017-01-21 22:37:47.774891</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>803683</td>\n",
       "      <td>2017-01-09 06:05:16.222706</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>944475</td>\n",
       "      <td>2017-01-22 01:31:09.573836</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>718956</td>\n",
       "      <td>2017-01-22 11:45:11.327945</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>644214</td>\n",
       "      <td>2017-01-22 02:05:21.719434</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>847721</td>\n",
       "      <td>2017-01-17 14:01:00.090575</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>888545</td>\n",
       "      <td>2017-01-08 06:37:26.332945</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>650559</td>\n",
       "      <td>2017-01-24 11:55:51.084801</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>935734</td>\n",
       "      <td>2017-01-17 20:33:37.428378</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id                   timestamp      group landing_page  converted  \\\n",
       "0    851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1    804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2    661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3    853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4    864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "5    936923  2017-01-10 15:20:49.083499    control     old_page          0   \n",
       "6    679687  2017-01-19 03:26:46.940749  treatment     new_page          1   \n",
       "7    719014  2017-01-17 01:48:29.539573    control     old_page          0   \n",
       "8    817355  2017-01-04 17:58:08.979471  treatment     new_page          1   \n",
       "9    839785  2017-01-15 18:11:06.610965  treatment     new_page          1   \n",
       "10   929503  2017-01-18 05:37:11.527370  treatment     new_page          0   \n",
       "11   834487  2017-01-21 22:37:47.774891  treatment     new_page          0   \n",
       "12   803683  2017-01-09 06:05:16.222706  treatment     new_page          0   \n",
       "13   944475  2017-01-22 01:31:09.573836  treatment     new_page          0   \n",
       "14   718956  2017-01-22 11:45:11.327945  treatment     new_page          0   \n",
       "15   644214  2017-01-22 02:05:21.719434    control     old_page          1   \n",
       "16   847721  2017-01-17 14:01:00.090575    control     old_page          0   \n",
       "17   888545  2017-01-08 06:37:26.332945  treatment     new_page          1   \n",
       "18   650559  2017-01-24 11:55:51.084801    control     old_page          0   \n",
       "19   935734  2017-01-17 20:33:37.428378    control     old_page          0   \n",
       "\n",
       "    intercept  ab_page country  canada  USA  \n",
       "0           1        0      US       0    1  \n",
       "1           1        0      US       0    1  \n",
       "2           1        1      US       0    1  \n",
       "3           1        1      US       0    1  \n",
       "4           1        0      US       0    1  \n",
       "5           1        0      US       0    1  \n",
       "6           1        1      CA       1    0  \n",
       "7           1        0      US       0    1  \n",
       "8           1        1      UK       0    0  \n",
       "9           1        1      CA       1    0  \n",
       "10          1        1      UK       0    0  \n",
       "11          1        1      US       0    1  \n",
       "12          1        1      US       0    1  \n",
       "13          1        1      US       0    1  \n",
       "14          1        1      US       0    1  \n",
       "15          1        0      US       0    1  \n",
       "16          1        0      US       0    1  \n",
       "17          1        1      US       0    1  \n",
       "18          1        0      CA       1    0  \n",
       "19          1        0      US       0    1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read and examine countries csv file\n",
    "countries = pd.read_csv('countries.csv')\n",
    "countries.head()\n",
    "#create a new dataframe by merging on the user ids of both tables\n",
    "df4 = df3.merge(countries,how='inner',left_on='user_id',right_on='user_id')\n",
    "#create dummy variables for country column\n",
    "countries_dum = pd.get_dummies(df4['country'])\n",
    "#add 2 dummy variables to dataframe (using UK users as the baseline)\n",
    "df4['canada'] = countries_dum.iloc[:,[0]]\n",
    "df4['USA'] = countries_dum.iloc[:,[2]]\n",
    "#check to make sure variables added correctly\n",
    "df4.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366116\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>          <td>AIC:</td>        <td>212780.8333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2020-07-31 15:49</td>       <td>BIC:</td>        <td>212812.5723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>       <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>2</td>            <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290581</td>        <td>LLR p-value:</td>      <td>0.19835</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-1.9868</td>  <td>0.0114</td>  <td>-174.1736</td> <td>0.0000</td> <td>-2.0092</td> <td>-1.9645</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>canada</th>    <td>-0.0507</td>  <td>0.0284</td>   <td>-1.7863</td>  <td>0.0740</td> <td>-0.1064</td> <td>0.0049</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>USA</th>       <td>-0.0099</td>  <td>0.0133</td>   <td>-0.7458</td>  <td>0.4558</td> <td>-0.0360</td> <td>0.0161</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.000      \n",
       "Dependent Variable: converted        AIC:              212780.8333\n",
       "Date:               2020-07-31 15:49 BIC:              212812.5723\n",
       "No. Observations:   290584           Log-Likelihood:   -1.0639e+05\n",
       "Df Model:           2                LL-Null:          -1.0639e+05\n",
       "Df Residuals:       290581           LLR p-value:      0.19835    \n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "No. Iterations:     6.0000                                        \n",
       "-------------------------------------------------------------------\n",
       "              Coef.   Std.Err.      z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept    -1.9868    0.0114  -174.1736  0.0000  -2.0092  -1.9645\n",
       "canada       -0.0507    0.0284    -1.7863  0.0740  -0.1064   0.0049\n",
       "USA          -0.0099    0.0133    -0.7458  0.4558  -0.0360   0.0161\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create another logistic regression\n",
    "logmod2 = sm.Logit(df4['converted'],df4[['intercept','canada','USA']])\n",
    "res = logmod2.fit()\n",
    "#show results\n",
    "res.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results for regression with added country variable:\n",
    "\n",
    "From the above logistic regression, we can see that the variables for **users from Canada and users from USA have p-values above the significance value**.\n",
    "\n",
    "Thus we are **not able to reject the null hypothesis for each of these coefficients** and **cannot say with statistical significance that there is a significant difference between each variable and the baseline variable of users from the UK on whether a user will convert or not**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we have now looked at the individual factors of country and page on conversion, we would now like to look at an **interaction between page and country** to see if there significant effects on conversion.  We will create the necessary additional columns, and fit the new model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366109\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>          <td>AIC:</td>        <td>212777.1060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2020-07-31 15:49</td>       <td>BIC:</td>        <td>212808.8450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>       <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>2</td>            <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290581</td>        <td>LLR p-value:</td>     <td>0.030766</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>          <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>       <td>-1.9873</td>  <td>0.0072</td>  <td>-275.5728</td> <td>0.0000</td> <td>-2.0014</td> <td>-1.9732</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>int_can_ab_page</th> <td>-0.0842</td>  <td>0.0378</td>   <td>-2.2251</td>  <td>0.0261</td> <td>-0.1583</td> <td>-0.0100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>int_USA_ab_page</th> <td>-0.0197</td>  <td>0.0121</td>   <td>-1.6337</td>  <td>0.1023</td> <td>-0.0434</td> <td>0.0039</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.000      \n",
       "Dependent Variable: converted        AIC:              212777.1060\n",
       "Date:               2020-07-31 15:49 BIC:              212808.8450\n",
       "No. Observations:   290584           Log-Likelihood:   -1.0639e+05\n",
       "Df Model:           2                LL-Null:          -1.0639e+05\n",
       "Df Residuals:       290581           LLR p-value:      0.030766   \n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "No. Iterations:     6.0000                                        \n",
       "------------------------------------------------------------------\n",
       "                  Coef.  Std.Err.     z     P>|z|   [0.025  0.975]\n",
       "------------------------------------------------------------------\n",
       "intercept        -1.9873   0.0072 -275.5728 0.0000 -2.0014 -1.9732\n",
       "int_can_ab_page  -0.0842   0.0378   -2.2251 0.0261 -0.1583 -0.0100\n",
       "int_USA_ab_page  -0.0197   0.0121   -1.6337 0.1023 -0.0434  0.0039\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new column for the interaction variables\n",
    "df4['int_can_ab_page']=df4['canada']*df4['ab_page']\n",
    "df4['int_USA_ab_page']=df4['USA']*df4['ab_page']\n",
    "#create a new logarithmic regression\n",
    "logmod3 = sm.Logit(df4['converted'],df4[['intercept','int_can_ab_page','int_USA_ab_page']])\n",
    "res = logmod3.fit()\n",
    "#show results\n",
    "res.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression results with interaction variable:\n",
    "\n",
    "After observing the results from the above logistic regression seeing if there is an interaction between country and whether a person was shown the new page, we can see that the as the coefficient for the **interaction between canada and ab_page, is below the signigicance level of 0.05, we reject the null hypothesis that this coefficient could be zero. **\n",
    "\n",
    "As such it seems there is some **significant interaction between users from Canada and whether they were shown the new page and whether they will convert or not** meaning they are less likely to converrt compared to users from the UK. \n",
    "\n",
    "### Inferences:\n",
    "\n",
    "From the above logistic regression, we can see that the values of the coefficient for when users were shown the new page, do not have a statistically significant impact on whether a user converts or not. \n",
    "\n",
    "However it could be that users from the UK are more likely to be converted when shown the new page as compared to users from the USA and Canada. But this would need to be investigated in more detail. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "### Part IV - Conclusions\n",
    "\n",
    "For our dataset we looked at some probabilities, two sets of hypothesis tests as well as some logarithmic regressions. From all the evidence gathered, **we can conclude with relative certainty that whether a user was shown the new page design, had no significant impact on whether the user would then convert or not**.\n",
    "\n",
    "For the practical significance of these results, we can say that in terms of getting more users to convert, **it is not beneficial for this company to invest more time and resources in implementing the new page design as there is not a signifcant return on investment.** However perhaps the new page design is better when different metrics are examined such as total number of page visitors or length of time spent on the page and further analysis' could be undertaken to investigate.\n",
    "\n",
    "It could also be worth investigating the difference in user behaviour from different countries, as perhaps targeted advertising could be beneficial if there is a difference in user behaviour across different countries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Analyze_ab_test_results_notebook.ipynb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
